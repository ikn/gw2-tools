#! /usr/bin/env bash

shopt -s nullglob

LOGS_PATH="$GW2_DPSREPORT_LOGS_PATH"
URL="${GW2_DPSREPORT_URL:-https://dps.report}"

# where the day boundary falls, as %H%M%S/%H:%M:%S
DAY_START_NUM=050000
DAY_START_TIME=05:00:00
# min bytes for file to be counted as an attempt (2MB/300kB)
ATTEMPTS_THRESHOLD_RAW=2000000
ATTEMPTS_THRESHOLD_ZIP=300000
TEMP_DIR="$(mktemp -d)"

DAY="$1"

[ -z "$LOGS_PATH" ] && {
    echo >&2 "error: environment variable not set: GW2_DPSREPORT_LOGS_PATH"
    exit 2
}
[ -d "$LOGS_PATH" ] || {
    echo >&2 "error: not a directory: $LOGS_PATH"
    exit 2
}
[ "$#" -ne 1 ] && {
    echo >&2 "usage: gw2-dpsreport DAY"
    echo >&2 "DAY: eg. 'today', 'last wednesday', '2001-02-03'"
    exit 2
}
date &> /dev/null --date="$DAY" "+%Y%m%d %H:%M:%S" || {
    echo >&2 "error: invalid day: $DAY"
    exit 2
}
type -p zip > /dev/null || {
    echo >&2 -n "warning: zip not found; "
    echo >&2 "uncompressed logs will be uploaded without compression"
}

# given log file path, print boss name
parse_path_boss_name () {
    local f="$1"
    echo "$(basename "$(dirname "$f")")"
}

# given log file path, print date as %Y%m%d%H%M%S
parse_path_date () {
    local f="$1"
    local date="$(basename "$f")"
    date="${date/-/}"
    echo "${date%.*}"
}

# remove all created temporary files
cleanup () {
    rm -rf "$TEMP_DIR"
}

# filter log files to those that were recorded on the day specified in $DAY
# read lines: FILE_PATH
# write lines: FILE_PATH
filter_logs_time () {
    local time_num="$(date --date="$DAY" +%H%M%S)"
    local date_unixtime="$(date --date="$DAY" +%s)"
    local day="$(date --date="$DAY" +%Y%m%d)"

    # move back 1 day if time falls before the threshold
    # however, if time is midnight exactly, it's very likely that the user
    # specified a date without a time, in which case we don't want to move back
    local start_unixtime
    local end_unixtime
    if [ "$time_num" -lt "$DAY_START_NUM" ] && [ "$time_num" != 000000 ]; then
        local day_start="$(
            date --date="@$((date_unixtime - 24*60*60))" "+%Y%m%d")"
        start_unixtime="$(date --date="$day_start $DAY_START_TIME" +%s)"
        end_unixtime="$(date --date="$day $DAY_START_TIME" +%s)"
    else
        local day_end="$(
            date --date="@$((date_unixtime + 24*60*60))" "+%Y%m%d")"
        start_unixtime="$(date --date="$day $DAY_START_TIME" +%s)"
        end_unixtime="$(date --date="$day_end $DAY_START_TIME" +%s)"
    fi

    local f
    while read -r f; do
        local name="$(basename "$f")"
        local file_date_raw="${name%%.*}" # %Y%m%d-%H%M%S
        local file_time="${file_date_raw#*-}" # %H%M%S
        local file_date="${file_date_raw%-*} ${file_time:0:2}:${file_time:2:2}:${file_time:4:2}"
        local file_unixtime="$(date --date="$file_date" +%s)"
        [ "$file_unixtime" -ge "$start_unixtime" ] &&
            [ "$file_unixtime" -lt "$end_unixtime" ] &&
            echo "$f"
    done
}

# filter log files to those above the small-file threshold
# read lines: FILE_PATH
# write lines: FILE_PATH
filter_logs_size () {
    local f
    while read -r f; do
        local size="$(stat --format=%s "$f")"
        local ext="${f##*.}"
        local limit
        if [ "$ext" = evtc ]; then
            limit="$ATTEMPTS_THRESHOLD_RAW"
        elif [ "$ext" = zip ]; then
            limit="$ATTEMPTS_THRESHOLD_ZIP"
        else
            limit=0
        fi

        if [ "$size" -ge "$limit" ]; then
            echo "$f"
        fi
    done
}

# filter log files to the last attempt at each encounter, and count attempts
# read lines: FILE_PATH
# write lines: NUM_BOSS_ATTEMPTS FILE_PATH
filter_logs_grouped () {
    {
        local prev_boss_name=
        local num_attempts=0
        local prev_f
        local f

        while read -r f; do
            local boss_name="$(parse_path_boss_name "$f")"
            if [ "$boss_name" = "$prev_boss_name" ]; then
                num_attempts="$((num_attempts + 1))"
            else
                [ "$num_attempts" != 0 ] &&
                    echo "$(parse_path_date "$prev_f") $num_attempts $prev_f"
                prev_boss_name="$boss_name"
                num_attempts=1
            fi
            prev_f="$f"
        done

        [ "$num_attempts" != 0 ] &&
            echo "$(parse_path_date "$prev_f") $num_attempts $prev_f"

    } < <(sort) |
        sort -n |
        while read -r date num_attempts f; do
            echo "$num_attempts" "$f"
        done
}

# compress_log LOG_FILE TMP_FILE
#
# compress LOG_FILE, if necessary, and write the result to TMP_FILE
# prints the new file path, which might be LOG_FILE or TMP_FILE
compress_log () {
    local file="$1"
    local tmp_file="$2"
    local ext="${file##*.}"

    if type -p zip > /dev/null &&
        [ "$ext" = evtc ] &&
        zip -q - -- "$file" > "$tmp_file"
    then
        echo "$tmp_file"
    else
        echo "$file"
    fi
}

# upload log file at the given path, and print the URL if it succeeded
upload_log () {
    local file="$1"
    local tmp_file
    # curl uses filename as multipart filename by default, and the server uses
    # the extension to determine file type
    tmp_file="$(mktemp -p "$TEMP_DIR" -q --suffix=.zip)" &&
        file="$(compress_log "$file" "$tmp_file")"

    local url="$URL"/uploadContent
    local res
    res="$(
        curl --progress-bar "$url" -F file=@"$file" -F json=1
    )"
    local err_code="$?"
    [ -n "$tmp_file" ] && rm -f "$tmp_file"
    [ "$err_code" -ne 0 ] && return 1

    local err
    err="$(jshon -e error <<<"$res")"
    if [ "$?" != 0 ] || [ "$err" != null ]; then
        echo >&2 "error: $file: ${err:-unknown}"
        return 1
    fi

    local link
    link="$(jshon -e permalink -u <<<"$res")" || {
        echo >&2 "error: $file: unexpected HTTP response: $res"
        return 1
    }
    echo "$link"
}

# upload log files; failed uploads are also printed, but without the upload URL
# read lines: NUM_BOSS_ATTEMPTS FILE_PATH
# write lines: NUM_BOSS_ATTEMPTS/BOSS_NAME/[URL]
upload_logs () {
    local num_attempts
    local f
    while read -r num_attempts f; do
        echo "$num_attempts/$(parse_path_boss_name "$f")/$(upload_log "$f")"
    done
}

# read standard input until EOF, then print it
buffer_input () {
    local input="$(cat)"
    if [ -n "$input" ]; then
        echo >&2
        echo "$input"
    else
        echo >&2 "(no logs found)"
    fi
}

# print log upload results in a human-readable format
# read lines: NUM_BOSS_ATTEMPTS/BOSS_NAME/[URL]
display_results () {
    local line
    while read -r line; do
        local num_attempts="${line%%/*}"; line="${line#*/}"
        local boss_name="${line%%/*}"
        local url="${line#*/}"
        echo "$boss_name (attempts: $num_attempts): ${url:-[upload failed]}"
    done
}

trap cleanup TERM INT EXIT
for f in "$LOGS_PATH"/*/*.evtc{,.zip}; do echo "$f"; done |
    filter_logs_time |
    filter_logs_size |
    filter_logs_grouped |
    upload_logs |
    buffer_input |
    display_results
for c in "${PIPESTATUS[@]}"; do
    [ "$c" != 0 ] && exit "$c"
done
