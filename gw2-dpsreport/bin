#! /usr/bin/env bash

shopt -s nullglob

LOGS_PATH="$GW2_DPSREPORT_LOGS_PATH"
URL="${GW2_DPSREPORT_URL:-https://dps.report}"

# where the day boundary falls, as %H%M%S/%H:%M:%S
DAY_START_NUM=050000
DAY_START_TIME=05:00:00
# min bytes for file to be counted as an attempt (2MB/300kB)
ATTEMPTS_THRESHOLD_RAW=2000000
ATTEMPTS_THRESHOLD_ZIP=300000

DAY="$1"

[ -z "$LOGS_PATH" ] && {
    echo >&2 "error: environment variable not set: GW2_DPSREPORT_LOGS_PATH"
    exit 2
}
[ -d "$LOGS_PATH" ] || {
    echo >&2 "error: not a directory: $LOGS_PATH"
    exit 2
}
[ "$#" -ne 1 ] && {
    echo >&2 "usage: gw2-dpsreport DAY"
    echo >&2 "DAY: eg. 'today', 'last wednesday', '2001-02-03'"
    exit 2
}

# given log file path, print boss name
parse_path_boss_name () {
    local f="$1"
    echo "$(basename "$(dirname "$f")")"
}

# given log file path, print date as %Y%m%d%H%M%S
parse_path_date () {
    local f="$1"
    local date="$(basename "$f")"
    date="${date/-/}"
    echo "${date%.*}"
}

# filter log files to those that were recorded on the day specified in $DAY
# read lines: FILE_PATH
# write lines: FILE_PATH
filter_logs_time () {
    local date
    date="$(date --date="$DAY" +%Y%m%d-%H%M%S)" || {
        echo >&2 "error: invalid day: $DAY"
        return 2
    }
    local day="${date%-*}" # %Y%m%d
    local time="${date#*-}" # %H%M%S
    # move back 1 day if time falls before the threshold
    # however, if time is midnight exactly, it's very likely that the user
    # specified a date without a time, in which case we don't want to move back
    [ "$time" -lt "$DAY_START_NUM" ] &&
        [ "$time" != 000000 ] &&
        day="$((day - 1))"
    local start_unixtime="$(date --date="$day $DAY_START_TIME" +%s)"
    local end_unixtime="$(date --date="$((day + 1)) $DAY_START_TIME" +%s)"

    local f
    while read -r f; do
        local name="$(basename "$f")"
        local file_date="${name%%.*}" # %Y%m%d-%H%M%S
        local file_time="${file_date#*-}" # %H%M%S
        # %Y%m%d %H:%M:%S
        local parseable_file_date="${file_date%-*} ${file_time:0:2}:${file_time:2:2}:${file_time:4:2}"
        local file_unixtime="$(date --date="$parseable_file_date" +%s)"
        [ "$file_unixtime" -ge "$start_unixtime" ] &&
            [ "$file_unixtime" -lt "$end_unixtime" ] &&
            echo "$f"
    done
}

# filter log files to those above the small-file threshold
# read lines: FILE_PATH
# write lines: FILE_PATH
filter_logs_size () {
    local f
    while read -r f; do
        local size="$(stat --format=%s "$f")"
        local ext="${f##*.}"
        local limit
        if [ "$ext" = evtc ]; then
            limit="$ATTEMPTS_THRESHOLD_RAW"
        elif [ "$ext" = zip ]; then
            limit="$ATTEMPTS_THRESHOLD_ZIP"
        else
            limit=0
        fi

        if [ "$size" -ge "$limit" ]; then
            echo "$f"
        fi
    done
}

# filter log files to the last attempt at each encounter, and count attempts
# read lines: FILE_PATH
# write lines: NUM_BOSS_ATTEMPTS FILE_PATH
filter_logs_grouped () {
    {
        local prev_boss_name=
        local num_attempts=0
        local prev_f
        local f

        while read -r f; do
            local boss_name="$(parse_path_boss_name "$f")"
            if [ "$boss_name" = "$prev_boss_name" ]; then
                num_attempts="$((num_attempts + 1))"
            else
                [ "$num_attempts" != 0 ] &&
                    echo "$(parse_path_date "$prev_f") $num_attempts $prev_f"
                prev_boss_name="$boss_name"
                num_attempts=1
            fi
            prev_f="$f"
        done

        [ "$num_attempts" != 0 ] &&
            echo "$(parse_path_date "$prev_f") $num_attempts $prev_f"

    } < <(sort) |
        sort -n |
        while read -r date num_attempts f; do
            echo "$num_attempts" "$f"
        done
}

# upload log file at the given path, and print the URL if it succeeded
upload_log () {
    local file="$1"
    local url="$URL"/uploadContent
    local res
    res="$(
        curl --progress-bar "$url" -F file=@"$file" -F json=1
    )" || return 1

    local err
    err="$(jshon -e error <<<"$res")"
    if [ "$?" != 0 ] || [ "$err" != null ]; then
        echo >&2 "error: $file: ${err:-unknown}"
        return 1
    fi

    local link
    link="$(jshon -e permalink -u <<<"$res")" || {
        echo >&2 "error: $file: unexpected HTTP response: $res"
        return 1
    }
    echo "$link"
}

# upload log files; failed uploads are also printed, but without the upload URL
# read lines: NUM_BOSS_ATTEMPTS FILE_PATH
# write lines: NUM_BOSS_ATTEMPTS/BOSS_NAME/[URL]
upload_logs () {
    local num_attempts
    local f
    while read -r num_attempts f; do
        echo "$num_attempts/$(parse_path_boss_name "$f")/$(upload_log "$f")"
    done
}

# read standard input until EOF, then print it
buffer_input () {
    local input="$(cat)"
    if [ -n "$input" ]; then
        echo >&2
        echo "$input"
    else
        echo >&2 "(no logs found)"
    fi
}

# print log upload results in a human-readable format
# read lines: NUM_BOSS_ATTEMPTS/BOSS_NAME/[URL]
display_results () {
    local line
    while read -r line; do
        local num_attempts="${line%%/*}"; line="${line#*/}"
        local boss_name="${line%%/*}"
        local url="${line#*/}"
        echo "$boss_name (attempts: $num_attempts): ${url:-[upload failed]}"
    done
}

for f in "$LOGS_PATH"/*/*.evtc{,.zip}; do echo "$f"; done |
    filter_logs_time |
    filter_logs_size |
    filter_logs_grouped |
    upload_logs |
    buffer_input |
    display_results
for c in "${PIPESTATUS[@]}"; do
    [ "$c" != 0 ] && exit "$c"
done
